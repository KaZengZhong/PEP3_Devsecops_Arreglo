version: '3.8'

services:
  # Frontend service
  frontend:
    image: kahaozeng/prestabanco-frontend:latest
    container_name: frontend-1
    ports:
      - "8070:80"
    depends_on:
      - backend
    networks:
      - app-network

  # Backend service
  backend:
    image: kahaozeng/prestabanco-backend:latest
    container_name: backend-1
    environment:
      DB_HOST: postgres
      SPRING_DATASOURCE_URL: jdbc:postgresql://postgres:5432/prestabanco
      SPRING_DATASOURCE_USERNAME: postgres
      SPRING_DATASOURCE_PASSWORD: admin
      SPRING_JPA_SHOW_SQL: "true"
      SPRING_JPA_HIBERNATE_DDL_AUTO: "update"
    ports:
      - "8090:8090"
    depends_on:
      - postgres
    networks:
      - app-network

  # PostgreSQL 
  postgres:
    image: postgres:latest
    container_name: postgres-1
    environment:
      POSTGRES_DB: prestabanco
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin
    ports:
      - "0.0.0.0:5433:5432"
    volumes:
      - postgres:/var/lib/postgresql/data
    networks:
      - app-network

  # Elasticsearch - Tu configuración que funciona + mejoras
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    container_name: elasticsearch-1
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - cluster.routing.allocation.disk.threshold_enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s

  # Kibana - Tu configuración que funciona + mejoras
  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.0
    container_name: kibana-1
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200
      SERVER_NAME: kibana
      SERVER_PUBLICBASEURL: http://localhost:5601
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - app-network
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 120s

  # Logstash - Configuración mejorada pero manteniendo tu versión
  logstash:
    image: docker.elastic.co/logstash/logstash:8.11.0
    container_name: logstash-1
    ports:
      - "5044:5044"
    environment:
      LS_JAVA_OPTS: "-Xmx256m -Xms256m"
      PIPELINE_WORKERS: 1
    depends_on:
      elasticsearch:
        condition: service_healthy
    networks:
      - app-network
    command: >
      bash -c "
      echo 'input { 
        beats { port => 5044 }
        tcp { port => 5000 codec => json }
      }
      filter {
        if [docker][container][name] {
          mutate { add_field => { \"service_name\" => \"%{[docker][container][name]}\" } }
        }
        mutate { add_field => { \"application\" => \"prestabanco\" } }
        mutate { add_field => { \"environment\" => \"security-scan\" } }
      }
      output {
        elasticsearch {
          hosts => [\"elasticsearch:9200\"]
          index => \"prestabanco-logs-%{+YYYY.MM.dd}\"
        }
        stdout { codec => dots }
      }' > /usr/share/logstash/pipeline/logstash.conf &&
      /usr/local/bin/docker-entrypoint
      "

  # Filebeat - Mejorado para mejor recolección de logs
  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.0
    container_name: filebeat-1
    user: root
    volumes:
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - filebeat_data:/usr/share/filebeat/data
    depends_on:
      logstash:
        condition: service_started
    networks:
      - app-network
    command: >
      bash -c "
      echo 'filebeat.inputs:
      - type: container
        paths: [\"/var/lib/docker/containers/*/*.log\"]
        processors:
        - add_docker_metadata:
            host: \"unix:///var/run/docker.sock\"
        - decode_json_fields:
            fields: [\"message\"]
            target: \"\"
            overwrite_keys: true
        - drop_event:
            when:
              or:
                - contains:
                    docker.container.name: \"filebeat\"
                - contains:
                    docker.container.name: \"logstash\"
                - contains:
                    docker.container.name: \"elasticsearch\"
      output.logstash:
        hosts: [\"logstash:5044\"]
      logging.level: info
      logging.to_files: false' > /usr/share/filebeat/filebeat.yml &&
      filebeat -e
      "

networks:
  app-network:
    driver: bridge

volumes:
  postgres:
    external: true
  elasticsearch_data:
    driver: local
  filebeat_data:
    driver: local